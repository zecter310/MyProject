{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepocessing"
      ],
      "metadata": {
        "id": "dCSKSbMna-p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import VarianceThreshold"
      ],
      "metadata": {
        "id": "FHkEF8DzPuNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bot-Iot**"
      ],
      "metadata": {
        "id": "_VIbjQPMBoOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv(\"/content/Bot-Iot.csv_0_row_100000.csv\")\n",
        "data2 = pd.read_csv(\"/content/Bot-Iot.csv_9_row_100000.csv\")\n",
        "data3 = pd.read_csv(\"/content/Bot-Iot.csv_1_row_100000.csv\")\n",
        "data4 = pd.read_csv(\"/content/Bot-Iot.csv_2_row_100000.csv\")\n",
        "data5 = pd.read_csv(\"/content/Bot-Iot.csv_3_row_100000.csv\")\n",
        "data6 = pd.read_csv(\"/content/Bot-Iot.csv_4_row_100000.csv\")\n",
        "data7 = pd.read_csv(\"/content/Bot-Iot.csv_5_row_100000.csv\")\n",
        "data8 = pd.read_csv(\"/content/Bot-Iot.csv_6_row_100000.csv\")\n",
        "data9 = pd.read_csv(\"/content/Bot-Iot.csv_7_row_100000.csv\")\n",
        "data10 = pd.read_csv(\"/content/Bot-Iot.csv_8_row_100000.csv\")\n",
        "\n",
        "data = pd.concat([data1, data2, data3, data4, data5, data6, data7, data8, data9, data10])"
      ],
      "metadata": {
        "id": "M1uZFPF6smql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(frac=0.2, random_state=10)"
      ],
      "metadata": {
        "id": "QLBiXKeRWTBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq8DcVHG54E5",
        "outputId": "6e55d459-2b15-4562-fd81-16c896bd26df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 48)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLG-ex9Bz-LI",
        "outputId": "46fb7389-7871-43f1-d98c-631ec2fe4f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'row_id', 'pkSeqID', 'stime', 'flgs', 'flgs_number',\n",
              "       'proto', 'proto_number', 'saddr', 'sport', 'daddr', 'dport', 'pkts',\n",
              "       'bytes', 'state', 'state_number', 'ltime', 'seq', 'dur', 'mean',\n",
              "       'stddev', 'sum', 'min', 'max', 'spkts', 'dpkts', 'sbytes', 'dbytes',\n",
              "       'rate', 'srate', 'drate', 'TnBPSrcIP', 'TnBPDstIP', 'TnP_PSrcIP',\n",
              "       'TnP_PDstIP', 'TnP_PerProto', 'TnP_Per_Dport', 'AR_P_Proto_P_SrcIP',\n",
              "       'AR_P_Proto_P_DstIP', 'N_IN_Conn_P_DstIP', 'N_IN_Conn_P_SrcIP',\n",
              "       'AR_P_Proto_P_Sport', 'AR_P_Proto_P_Dport',\n",
              "       'Pkts_P_State_P_Protocol_P_DestIP', 'Pkts_P_State_P_Protocol_P_SrcIP',\n",
              "       'attack', 'category', 'subcategory'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['category'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPW5mvH2qaaT",
        "outputId": "1eb00aa0-66bc-436e-a846-62b1e2a04876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['DDoS', 'Reconnaissance', 'DoS', 'Theft', 'Normal'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "data = data.dropna()\n",
        "data['category'] = label_encoder.fit_transform(data['category'])\n",
        "data['subcategory'] = label_encoder.fit_transform(data['subcategory'])"
      ],
      "metadata": {
        "id": "R6sCY8nY0BBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.select_dtypes(include='number')"
      ],
      "metadata": {
        "id": "jAIsWY_M8Zw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data = data\n",
        "clean_data=clean_data.loc[:,(clean_data!=0).any(axis=0)]\n",
        "X,y= clean_data.drop(['category'],axis=1),clean_data['category']\n",
        "clean_data_nomialzion=X/X.mean()\n",
        "vt=VarianceThreshold(threshold=0.003) # Dùng model VT để đánh dấu các cột có gì gị threshold bé hơn 0.003\n",
        "_=vt.fit(clean_data_nomialzion)\n",
        "mask = vt.get_support() # Đánh dấu các cột có giá trị bé hơn 0.003 bằng mask\n",
        "X_reduced=X.loc[:, mask] # Xóa các cột\n",
        "\n",
        "def identify_correlated(df, threshold):\n",
        "    \"\"\"\n",
        "    A function to identify highly correlated features.\n",
        "    \"\"\"\n",
        "    # Tính ma trận tương quan\n",
        "    matrix = df.corr().abs()\n",
        "\n",
        "    mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
        "\n",
        "    # Tạo ra ma trận\n",
        "    reduced_matrix = matrix.mask(mask)\n",
        "\n",
        "    # Tìm các cột có threshold lơn hơn\n",
        "    to_drop = [c for c in reduced_matrix.columns if any(reduced_matrix[c] > threshold)]\n",
        "\n",
        "    return to_drop\n",
        "to_drop = identify_correlated(X_reduced, threshold=0.9)\n",
        "len(to_drop)\n",
        "X_reduced.drop(to_drop,axis=1,inplace= True)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X_reduced,y,test_size=0.3,random_state=1)\n",
        "rfecv = RFECV( # Init rfecv\n",
        "    estimator=LinearRegression(),\n",
        "    scoring=\"r2\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    min_features_to_select=5,\n",
        "    step=5,\n",
        ")\n",
        "\n",
        "_ = rfecv.fit(X_test,Y_test) # Fit\n",
        "\n",
        "mask = rfecv.support_ # Get a boolean mask for the features to keep\n",
        "X_final = X_reduced.loc[:, mask].copy()\n",
        "\n",
        "X_final.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot-prm-O-TAi",
        "outputId": "6052e125-17ee-44ff-a93d-d3274472566b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-7200376dd7ee>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_reduced.drop(to_drop,axis=1,inplace= True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_final.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdUe3wwF0Zj9",
        "outputId": "39334b9e-239b-427b-cd57-c7629f9c4cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['proto_number', 'stddev', 'min', 'max', 'subcategory'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_final = X_final.drop(['subcategory'],axis=1)"
      ],
      "metadata": {
        "id": "Pmzkychz_jwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_col = list(X_final.columns)\n",
        "arr_col.append('category')\n",
        "data = data[arr_col]"
      ],
      "metadata": {
        "id": "m0KC69xdWw38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iot**"
      ],
      "metadata": {
        "id": "XCoG8RZKA_cH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv(\"/content/Iot.csv_0_row_100000.csv\")\n",
        "data2 = pd.read_csv(\"/content/Iot.csv_1_row_100000.csv\")\n",
        "data3 = pd.read_csv(\"/content/Iot.csv_2_row_100000.csv\")\n",
        "data4 = pd.read_csv(\"/content/Iot.csv_3_row_100000.csv\")\n",
        "data5 = pd.read_csv(\"/content/Iot.csv_4_row_100000.csv\")\n",
        "data6 = pd.read_csv(\"/content/Iot.csv_5_row_100000.csv\")\n",
        "data7 = pd.read_csv(\"/content/Iot.csv_6_row_100000.csv\")\n",
        "data = pd.concat([data1, data2, data3, data4, data5, data6, data7])"
      ],
      "metadata": {
        "id": "T2d80ybZBCDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bneTsf8jBcyj",
        "outputId": "de575073-2a94-4576-c67a-92ca688dee8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(625783, 86)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Target'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHAvknsKCJHq",
        "outputId": "4ac3efe2-7d0c-4165-871e-6d846f82c5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['MITM ARP Spoofing', 'Normal', 'DoS', 'Scan', 'Mirai'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "data = data.dropna()\n",
        "data['Target'] = label_encoder.fit_transform(data['Target'])\n",
        "data = data.select_dtypes(include='number')"
      ],
      "metadata": {
        "id": "DSm9BLUuCh8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Target'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMBFbQEgCue9",
        "outputId": "cd27fa46-c6c3-43d8-d7ab-743625bf2037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 0, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGWMxhovCz2V",
        "outputId": "e4d344a9-0b9f-498d-a94a-0cba8782b314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    415677\n",
              "4     75265\n",
              "0     59391\n",
              "3     40073\n",
              "1     35377\n",
              "Name: Target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data = data\n",
        "clean_data=clean_data.loc[:,(clean_data!=0).any(axis=0)]\n",
        "X,y= clean_data.drop(['Target'],axis=1),clean_data['Target']\n",
        "clean_data_nomialzion=X/X.mean()\n",
        "vt=VarianceThreshold(threshold=0.003) # Dùng model VT để đánh dấu các cột có gì gị threshold bé hơn 0.003\n",
        "_=vt.fit(clean_data_nomialzion)\n",
        "mask = vt.get_support() # Đánh dấu các cột có giá trị bé hơn 0.003 bằng mask\n",
        "X_reduced=X.loc[:, mask] # Xóa các cột\n",
        "\n",
        "def identify_correlated(df, threshold):\n",
        "    \"\"\"\n",
        "    A function to identify highly correlated features.\n",
        "    \"\"\"\n",
        "    # Tính ma trận tương quan\n",
        "    matrix = df.corr().abs()\n",
        "\n",
        "    mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
        "\n",
        "    # Tạo ra ma trận\n",
        "    reduced_matrix = matrix.mask(mask)\n",
        "\n",
        "    # Tìm các cột có threshold lơn hơn\n",
        "    to_drop = [c for c in reduced_matrix.columns if any(reduced_matrix[c] > threshold)]\n",
        "\n",
        "    return to_drop\n",
        "to_drop = identify_correlated(X_reduced, threshold=0.8)\n",
        "len(to_drop)\n",
        "X_reduced.drop(to_drop,axis=1,inplace= True)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X_reduced,y,test_size=0.3,random_state=1)\n",
        "rfecv = RFECV( # Init rfecv\n",
        "    estimator=LinearRegression(),\n",
        "    scoring=\"r2\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    min_features_to_select=5,\n",
        "    step=5,\n",
        ")\n",
        "\n",
        "_ = rfecv.fit(X_test,Y_test) # Fit\n",
        "\n",
        "mask = rfecv.support_ # Get a boolean mask for the features to keep\n",
        "X_final = X_reduced.loc[:, mask].copy()\n",
        "\n",
        "X_final.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1HFDV86C4gB",
        "outputId": "07285b14-3732-4164-90ad-9b563032ff99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-6abdfd450e7e>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_reduced.drop(to_drop,axis=1,inplace= True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(625783, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_final.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "447TOO3UD60x",
        "outputId": "5ce48b4c-0fff-4fe3-d629-318766784527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['row_id', 'Src_Port', 'Dst_Port', 'Protocol', 'Fwd_Pkt_Len_Std',\n",
              "       'Bwd_Pkt_Len_Std', 'Fwd_IAT_Max', 'Fwd_IAT_Min', 'Bwd_IAT_Std',\n",
              "       'Bwd_IAT_Min', 'Fwd_Pkts/s', 'Bwd_Pkts/s', 'Pkt_Len_Var',\n",
              "       'FIN_Flag_Cnt', 'SYN_Flag_Cnt', 'RST_Flag_Cnt', 'PSH_Flag_Cnt',\n",
              "       'ACK_Flag_Cnt', 'URG_Flag_Cnt', 'CWE_Flag_Count', 'ECE_Flag_Cnt',\n",
              "       'Down/Up_Ratio', 'Fwd_Seg_Size_Avg', 'Bwd_Seg_Size_Avg',\n",
              "       'Subflow_Fwd_Byts', 'Subflow_Bwd_Pkts', 'Subflow_Bwd_Byts',\n",
              "       'Init_Bwd_Win_Byts', 'Fwd_Act_Data_Pkts', 'Active_Std', 'Active_Max',\n",
              "       'Active_Min', 'Idle_Std', 'Idle_Max', 'Idle_Min'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_final = X_final.drop(['row_id', 'Src_Port', 'Dst_Port', 'Protocol'],axis=1)"
      ],
      "metadata": {
        "id": "nD0fxx2nsWG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_col = list(X_final.columns)\n",
        "arr_col.append('Target')\n",
        "data = data[arr_col]"
      ],
      "metadata": {
        "id": "9RtTMtypEXYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CIC-IDS-2017**"
      ],
      "metadata": {
        "id": "83rHQvdLthjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv(\"/content/CIC-IDS-2017.csv_0_row_100000.csv\")\n",
        "data2 = pd.read_csv(\"/content/CIC-IDS-2017.csv_1_row_100000.csv\")\n",
        "data3 = pd.read_csv(\"/content/CIC-IDS-2017.csv_2_row_100000.csv\")\n",
        "data4 = pd.read_csv(\"/content/CIC-IDS-2017.csv_3_row_100000.csv\")\n",
        "data5 = pd.read_csv(\"/content/CIC-IDS-2017.csv_4_row_100000.csv\")\n",
        "data6 = pd.read_csv(\"/content/CIC-IDS-2017.csv_5_row_100000.csv\")\n",
        "data7 = pd.read_csv(\"/content/CIC-IDS-2017.csv_6_row_100000.csv\")\n",
        "data8 = pd.read_csv(\"/content/CIC-IDS-2017.csv_7_row_100000.csv\")\n",
        "data9 = pd.read_csv(\"/content/CIC-IDS-2017.csv_8_row_100000.csv\")\n",
        "data10 = pd.read_csv(\"/content/CIC-IDS-2017.csv_9_row_100000.csv\")\n",
        "\n",
        "data = pd.concat([data1,data2,data3,data4,data5,data6,data7,data8,data9,data10])"
      ],
      "metadata": {
        "id": "XI1uRIEwthDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(frac=0.1,random_state=100)"
      ],
      "metadata": {
        "id": "1dZHcNmhN5-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvokckr3yDUn",
        "outputId": "540967a5-d8fd-4678-91d9-61b83635bad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 87)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Target'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWipWh_kyFiS",
        "outputId": "89abc104-a63a-4bea-f55d-b6eef5204646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BENIGN', 'DoS Hulk', 'DDoS', 'PortScan', 'DoS GoldenEye',\n",
              "       'DoS slowloris', 'FTP-Patator', 'DoS Slowhttptest',\n",
              "       'Web Attack - Brute Force', 'SSH-Patator', 'Bot',\n",
              "       'Web Attack - XSS', 'Infiltration'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "data = data.dropna()\n",
        "data['Target'] = label_encoder.fit_transform(data['Target'])\n",
        "data = data.select_dtypes(include='number')"
      ],
      "metadata": {
        "id": "ahY8ywkGybf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afbcf371-6481-4f22-c284-06eb13f9ac2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-bff177864a25>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Target'] = label_encoder.fit_transform(data['Target'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Target'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3-kYpNgy5_x",
        "outputId": "3a10c944-846f-422c-eb46-4803a39a6b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  4,  2,  9,  3,  6,  7,  5, 11, 10,  1, 12,  8])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data = data\n",
        "clean_data=clean_data.loc[:,(clean_data!=0).any(axis=0)]\n",
        "X,y= clean_data.drop(['Target'],axis=1),clean_data['Target']\n",
        "clean_data_nomialzion=X/X.mean()\n",
        "vt=VarianceThreshold(threshold=0.003) # Dùng model VT để đánh dấu các cột có gì gị threshold bé hơn 0.003\n",
        "_=vt.fit(clean_data_nomialzion)\n",
        "mask = vt.get_support() # Đánh dấu các cột có giá trị bé hơn 0.003 bằng mask\n",
        "X_reduced=X.loc[:, mask] # Xóa các cột\n",
        "\n",
        "def identify_correlated(df, threshold):\n",
        "    \"\"\"\n",
        "    A function to identify highly correlated features.\n",
        "    \"\"\"\n",
        "    # Tính ma trận tương quan\n",
        "    matrix = df.corr().abs()\n",
        "\n",
        "    mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
        "\n",
        "    # Tạo ra ma trận\n",
        "    reduced_matrix = matrix.mask(mask)\n",
        "\n",
        "    # Tìm các cột có threshold lơn hơn\n",
        "    to_drop = [c for c in reduced_matrix.columns if any(reduced_matrix[c] > threshold)]\n",
        "\n",
        "    return to_drop\n",
        "to_drop = identify_correlated(X_reduced, threshold=0.8)\n",
        "len(to_drop)\n",
        "X_reduced.drop(to_drop,axis=1,inplace= True)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X_reduced,y,test_size=0.3,random_state=1)\n",
        "rfecv = RFECV( # Init rfecv\n",
        "    estimator=LinearRegression(),\n",
        "    scoring=\"r2\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    min_features_to_select=5,\n",
        "    step=5,\n",
        ")\n",
        "\n",
        "_ = rfecv.fit(X_test,Y_test) # Fit\n",
        "\n",
        "mask = rfecv.support_ # Get a boolean mask for the features to keep\n",
        "X_final = X_reduced.loc[:, mask].copy()\n",
        "\n",
        "X_final.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UGyUGkcy2CI",
        "outputId": "9b9fa7a7-69d5-48ac-b724-9b4e07c9fae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-6abdfd450e7e>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_reduced.drop(to_drop,axis=1,inplace= True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99949, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_final.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNZPaOHF0zDh",
        "outputId": "78665760-e8a9-4506-aa82-c97e381bd929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['row_id', 'Source Port', 'Destination Port', 'Fwd Packet Length Min',\n",
              "       'Bwd Packet Length Min', 'Flow IAT Min', 'Bwd IAT Total', 'Bwd IAT Max',\n",
              "       'Bwd IAT Min', 'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length',\n",
              "       'FIN Flag Count', 'SYN Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
              "       'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n",
              "       'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Subflow Fwd Bytes',\n",
              "       'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'act_data_pkt_fwd',\n",
              "       'min_seg_size_forward', 'Active Std', 'Active Max', 'Active Min',\n",
              "       'Idle Std', 'Idle Min'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_final = X_final.drop(['row_id', 'Source Port', 'Destination Port'],axis=1)"
      ],
      "metadata": {
        "id": "MP9GD74zOkjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_col = list(X_final.columns)\n",
        "arr_col.append('Target')\n",
        "data = data[arr_col]"
      ],
      "metadata": {
        "id": "KgsC7ES_045t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chia dataset và gộp lại thành các subset"
      ],
      "metadata": {
        "id": "8I6V1M6p_eJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKX10QQvdwMx",
        "outputId": "ca5b66b4-8401-488b-9974-ff28e1efd861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93kxIjHNFGOz",
        "outputId": "840403dc-38bf-4b91-d040-7aee597dabbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['proto_number', 'stddev', 'min', 'max', 'category'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BxFga2mq4Mr",
        "outputId": "e87c0da5-e974-4350-ab22-79b9d3892528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    105002\n",
              "1     89875\n",
              "3      5083\n",
              "2        37\n",
              "4         3\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = list(data['category'].unique())\n",
        "print(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bKz4sBRv2sg",
        "outputId": "30881ee8-f015-4dff-aa9b-78a72e625684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 3, 1, 4, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_dataset = {}\n",
        "for i in arr:\n",
        "  temp = data[data['category'] == i]\n",
        "  dict_dataset[i] = temp"
      ],
      "metadata": {
        "id": "LUvYV0F3wM1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = []\n",
        "for i in range(len(arr)):\n",
        "  temp = []\n",
        "  for j in range(len(arr)):\n",
        "    if j != i :\n",
        "      tmp = dict_dataset[j]\n",
        "      temp.append(tmp)\n",
        "\n",
        "  dt = pd.concat(temp)\n",
        "\n",
        "  new_data.append(dt)"
      ],
      "metadata": {
        "id": "ugeeS_1fGmKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = data.shape[0] // len(arr)\n",
        "testset = []\n",
        "for i in range(len(arr)):\n",
        "  tmp = data.iloc[i*x:(i+1)*x]\n",
        "  testset.append(tmp)"
      ],
      "metadata": {
        "id": "Ji2Q8gSsxoE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib"
      ],
      "metadata": {
        "id": "Nxd7tcAplWHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "\n",
        "#Chọn loại thiết bị để huấn luyện\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkE3eoE5lZEp",
        "outputId": "ad100d64-afbb-466a-85aa-9a0ec8c5dd59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.1.0+cu118 and Flower 1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset,TensorDataset"
      ],
      "metadata": {
        "id": "ysADT8eynC27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_tensor(X,y):\n",
        "  X_train = X.to_numpy()\n",
        "  X_train = torch.tensor(X_train)\n",
        "  y_train = y.to_numpy()\n",
        "  y_train = torch.tensor(y_train)\n",
        "  return X_train, y_train\n",
        "\n",
        "\n",
        "class CustomTensorDataset(Dataset):\n",
        "    \"\"\"TensorDataset with support of transforms.\n",
        "    \"\"\"\n",
        "    def __init__(self, tensors, transform=None):\n",
        "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
        "        self.tensors = tensors\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.tensors[0][index]\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        y = self.tensors[1][index]\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.tensors[0].size(0)"
      ],
      "metadata": {
        "id": "YtjgDmuUndgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "def partition_dataset(data):\n",
        "  trainloaders = []\n",
        "  valloaders = []\n",
        "  testloaders = []\n",
        "  test_X = []\n",
        "  test_y = []\n",
        "  for dt in data:\n",
        "    X = dt.drop('category',axis=1)\n",
        "    y = dt['category']\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=10)\n",
        "    X_val, y_val = transform_to_tensor(X_val, y_val)\n",
        "    X_train, y_train = transform_to_tensor(X_train, y_train)\n",
        "    trainset = CustomTensorDataset(tensors=(X_train, y_train), transform=None)\n",
        "    valset = CustomTensorDataset(tensors=(X_val,y_val),transform=None)\n",
        "    trainloaders.append(DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True))\n",
        "    valloaders.append(DataLoader(valset, batch_size=BATCH_SIZE))\n",
        "\n",
        "\n",
        "  return trainloaders, valloaders"
      ],
      "metadata": {
        "id": "e1122EbxnkN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloaders, valloaders = partition_dataset(new_data)"
      ],
      "metadata": {
        "id": "mplbuESHvPTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param = 0\n",
        "trainloader = trainloaders[0]\n",
        "for feature,label in trainloader:\n",
        "  for j in feature:\n",
        "    param = len(j)\n",
        "    break\n",
        "  break\n",
        "print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsOVMckEXuh1",
        "outputId": "46445095-12b8-4201-ae0f-efd69ee74ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module): # nn.Module là một base class trong PyTorch để xây dựng các mô hình neural network\n",
        "    def __init__(self, x) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(x, 100)\n",
        "        self.fc2 = nn.Linear(100, 100)\n",
        "        self.fc3 = nn.Linear(100, 100)\n",
        "        self.fc4 = nn.Linear(100,len(arr))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.relu(self.fc1(x.float()))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kCj68ZFqz_qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Federated Learning"
      ],
      "metadata": {
        "id": "qArIJ3-NWT2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, trainloader,epochs: int,verbose=False):\n",
        "  criterion = torch.nn.CrossEntropyLoss() # Hàm mất mát để đánh giá sai số\n",
        "  optimizer = torch.optim.Adam(net.parameters()) # Dùng để điều chỉnh các tham số\n",
        "  net.train()\n",
        "  for epoch in range(epochs):\n",
        "    correct, total, epoch_loss = 0, 0, 0.0\n",
        "    for features, label in trainloader:\n",
        "      features, label = features.to(DEVICE), label.to(DEVICE)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(features)\n",
        "      loss = criterion(outputs, label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss\n",
        "      total += label.size(0)\n",
        "      correct += (torch.max(outputs.data, 1)[1] == label).sum().item()\n",
        "    epoch_loss /= len(trainloader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "    if verbose: # In ra kết quả nếu verbose = true\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "def test(net, testloader):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    dict_eval = {}\n",
        "    dict_all_eval = {}\n",
        "    for i in range(len(arr)):\n",
        "      dict_eval[i] = {'TP':0,'FP':0,'FN':0}\n",
        "      dict_all_eval[i] = {'precision': 0,'recall': 0,'f1-score': 0}\n",
        "    with torch.no_grad(): # Các phép tính trong vòng lặp không được ghi lại để tiết kiệm bộ nhớ\n",
        "        for features, label in testloader:\n",
        "            features, label = features.to(DEVICE), label.to(DEVICE)\n",
        "            outputs = net(features)\n",
        "            loss += criterion(outputs, label).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += label.size(0)\n",
        "            correct += (predicted == label).sum().item()\n",
        "            for i in dict_eval:\n",
        "              for j in range(len(label)):\n",
        "                if i == label[j]:\n",
        "                  if predicted[j] == label[j]:\n",
        "                    dict_eval[i]['TP'] += 1\n",
        "                  else:\n",
        "                    dict_eval[i]['FP'] += 1\n",
        "                else:\n",
        "                  if predicted[j] != label[j]:\n",
        "                    dict_eval[i]['FN'] += 1\n",
        "    for i in dict_eval:\n",
        "      t1 = 0\n",
        "      t2 = 0\n",
        "      if dict_eval[i]['TP'] + dict_eval[i]['FP'] != 0:\n",
        "        t1 = dict_eval[i]['TP'] / (dict_eval[i]['TP'] + dict_eval[i]['FP'])\n",
        "        dict_all_eval[i]['precision'] = t1\n",
        "      if dict_eval[i]['TP'] + dict_eval[i]['FN'] != 0:\n",
        "        t2 = dict_eval[i]['TP'] / (dict_eval[i]['TP'] + dict_eval[i]['FN'])\n",
        "        dict_all_eval[i]['recall'] = t2\n",
        "      if t1 + t2 != 0:\n",
        "        dict_all_eval[i]['f1-score'] = 2*t1*t2/(t1+t2)\n",
        "\n",
        "    print(dict_all_eval)\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "k_9mhPFnWNNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy tham số của mạng ở sau khi client chạy\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()] # Lấy tất cả các tham số của mạng sau đó chuyển chúng về dạng numpy\n",
        "\n",
        "# Cập nhật tham số của mạng lên server\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters) # Tạo một từ điển\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ],
      "metadata": {
        "id": "HEIBkOunXJ6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):#Client\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):#lấy tham số sau khi tổng hợp từ server\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):#điều chỉnh tham số để thực hiện huấn luyên\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):#đánh giá loss,accuracy\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        print(f\"Client-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "qXS-XBBcXMRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_fn(cid: str) -> FlowerClient:#hàm mô phỏng 1 máy client\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    net = Net(param).to(DEVICE)\n",
        "\n",
        "    # Note: each client gets a different trainloader/valloader, so each client\n",
        "    # will train and evaluate on their own unique data\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "\n",
        "    # Create a  single Flower client representing a single organization\n",
        "    return FlowerClient(net, trainloader, valloader)"
      ],
      "metadata": {
        "id": "wPfnU62yXOAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_config(server_round: int):\n",
        "    \"\"\"Return training configuration dict for each round.\n",
        "\n",
        "    Perform two rounds of training with one local epoch, increase to two local\n",
        "    epochs afterwards.\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        \"server_round\": server_round,  # The current round of federated learning\n",
        "        \"local_epochs\": 2,\n",
        "    }\n",
        "    return config"
      ],
      "metadata": {
        "id": "gt_dnyWhXPoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hàm đánh giá ở server\n",
        "def evaluate(\n",
        "    server_round: int,\n",
        "    parameters: fl.common.NDArrays,\n",
        "    config: Dict[str, fl.common.Scalar],\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    net = Net(param).to(DEVICE)\n",
        "\n",
        "    set_parameters(net, parameters)  # Update model with the latest parameters\n"
      ],
      "metadata": {
        "id": "LlhTMB3LXSGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = get_parameters(Net(param))\n",
        "\n",
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg( # Có thể tùy chọn chiến lược khác như FedAdagrad\n",
        "    fraction_fit=1.0,  # Tỷ lệ các thiết bị người dùng được chọn để huấn luyện\n",
        "    fraction_evaluate=0.5,  # Tỷ lệ các thiết bị người dùng được chọn để đánh giá hiệu suất\n",
        "    min_fit_clients=len(arr)-1,  # Số tối thiểu các thiết bị người dùng cần có trong quá trình huấn luyện\n",
        "    min_evaluate_clients=5,  # Số tối thiểu các thiết bị người dùng cần có trong quá trình đánh giá\n",
        "    min_available_clients=len(arr),  # Wait until all 10 clients are available\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        "    evaluate_fn=evaluate,  # Pass the evaluation function\n",
        "    on_fit_config_fn=fit_config,  # Pass the fit_config function\n",
        ")\n",
        "\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None # Xác định các tài nguyên của máy khách\n",
        "\n",
        "\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation( # Mô phỏng bằng cách gọi hàm\n",
        "    client_fn=client_fn, # Một hàm để tạo ra các máy khách\n",
        "    num_clients=len(arr), # Số lượng máy khách\n",
        "    config=fl.server.ServerConfig(num_rounds=5), # Cấu hình cho máy chủ\n",
        "    strategy=strategy, # Chiến lược huấn luyện và tổ chức dữ liệu\n",
        "    client_resources=client_resources, # Tài nguyên của máy khách (số lượng GPU)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTLbaJyEXUu0",
        "outputId": "cd03407f-bd62-4c4e-f09b-dc270e7732c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-09 16:16:57,741 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2023-12-09 16:16:59,797\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-12-09 16:17:02,666 | app.py:213 | Flower VCE: Ray initialized with resources: {'memory': 7866185319.0, 'object_store_memory': 3933092659.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'memory': 7866185319.0, 'object_store_memory': 3933092659.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0}\n",
            "INFO flwr 2023-12-09 16:17:02,671 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2023-12-09 16:17:02,676 | app.py:227 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2023-12-09 16:17:02,684 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2023-12-09 16:17:02,736 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2023-12-09 16:17:02,743 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-12-09 16:17:02,753 | server.py:272 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2023-12-09 16:17:02,766 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-12-09 16:17:02,798 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-12-09 16:17:02,803 | server.py:222 | fit_round 1: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 5 clients (out of 5)\n",
            "\u001b[2m\u001b[36m(pid=21643)\u001b[0m 2023-12-09 16:17:05.449211: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=21643)\u001b[0m 2023-12-09 16:17:05.449281: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=21643)\u001b[0m 2023-12-09 16:17:05.449318: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=21642)\u001b[0m 2023-12-09 16:17:08.991723: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "DEBUG flwr 2023-12-09 16:17:46,632 | server.py:236 | fit_round 1 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 5 results and 0 failures\n",
            "WARNING flwr 2023-12-09 16:17:46,651 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-12-09 16:17:46,660 | server.py:173 | evaluate_round 1: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=21642)\u001b[0m {0: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 1: {'precision': 0.5309330063538067, 'recall': 0.9000377928949358, 'f1-score': 0.667881932272313}, 2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}, 3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21642)\u001b[0m Client-side evaluation loss 0.01575748658807654 / accuracy 0.5013684210526316\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21642)\u001b[0m {0: {'precision': 0.8810991636798089, 'recall': 0.6573374215630348, 'f1-score': 0.7529455005819533}, 1: {'precision': 0.5252525252525253, 'recall': 0.7274963486816819, 'f1-score': 0.6100493118896445}, 2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}, 3: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}, 4: {'precision': 0, 'recall': 0.0, 'f1-score': 0}}\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21642)\u001b[0m Client-side evaluation loss 0.009631993345916271 / accuracy 0.697525\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-09 16:18:03,974 | server.py:187 | evaluate_round 1 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 5 results and 0 failures\n",
            "WARNING flwr 2023-12-09 16:18:03,977 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-12-09 16:18:03,979 | server.py:222 | fit_round 2: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 5 clients (out of 5)\n",
            "DEBUG flwr 2023-12-09 16:18:35,451 | server.py:236 | fit_round 2 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-12-09 16:18:35,471 | server.py:173 | evaluate_round 2: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=21642)\u001b[0m {0: {'precision': 0.7985252140818269, 'recall': 0.8047657860670279, 'f1-score': 0.8016333548248442}, 1: {'precision': 0.7736258840563569, 'recall': 0.7660747766626227, 'f1-score': 0.7698318140256575}, 2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}, 3: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21642)\u001b[0m Client-side evaluation loss 0.006464264505628245 / accuracy 0.786912579519803\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m {0: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 1: {'precision': 0.7707613421023297, 'recall': 0.9465434633812457, 'f1-score': 0.849655935119194}, 2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}, 3: {'precision': 0.26507177033492824, 'recall': 0.06291165114694526, 'f1-score': 0.10168869309838473}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m Client-side evaluation loss 0.01005509877675458 / accuracy 0.742421052631579\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-09 16:18:53,020 | server.py:187 | evaluate_round 2 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-12-09 16:18:53,026 | server.py:222 | fit_round 3: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 5 clients (out of 5)\n",
            "DEBUG flwr 2023-12-09 16:19:22,870 | server.py:236 | fit_round 3 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-12-09 16:19:22,890 | server.py:173 | evaluate_round 3: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m {0: {'precision': 0.8931969552806851, 'recall': 0.7868818105616094, 'f1-score': 0.8366755793226383}, 1: {'precision': 0.7172133429860221, 'recall': 0.8511664794131254, 'f1-score': 0.7784695357833654}, 2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}, 3: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m Client-side evaluation loss 0.005671757676063586 / accuracy 0.8119741432382516\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-09 16:19:40,131 | server.py:187 | evaluate_round 3 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-12-09 16:19:40,135 | server.py:222 | fit_round 4: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m {0: {'precision': 0.8930978828443938, 'recall': 0.7618237771298996, 'f1-score': 0.822254272103492}, 1: {'precision': 0.7143574857653232, 'recall': 0.8092196787656507, 'f1-score': 0.7588353889943075}, 2: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 3: {'precision': 0.24530168150346193, 'recall': 0.03255020343877149, 'f1-score': 0.057473928157589796}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m Client-side evaluation loss 0.006206981066665714 / accuracy 0.7966144075213162\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-09 16:20:09,824 | server.py:236 | fit_round 4 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-12-09 16:20:09,844 | server.py:173 | evaluate_round 4: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=21642)\u001b[0m {0: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 1: {'precision': 0.7979043584884629, 'recall': 0.9482678677883023, 'f1-score': 0.8666121855988378}, 2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}, 3: {'precision': 0.26507177033492824, 'recall': 0.07073544433094994, 'f1-score': 0.11167103406571255}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21642)\u001b[0m Client-side evaluation loss 0.00605011891063891 / accuracy 0.7680526315789473\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m {0: {'precision': 0.8924807747080604, 'recall': 0.8108073141279972, 'f1-score': 0.8496859040990645}, 1: {'precision': 0.7978117673328123, 'recall': 0.8250779355732595, 'f1-score': 0.8112158020206607}, 2: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 3: {'precision': 0.24530168150346193, 'recall': 0.04041062408342839, 'f1-score': 0.06939003917179631}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m Client-side evaluation loss 0.005323287255809971 / accuracy 0.8336708924061711\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21642)\u001b[0m {0: {'precision': 0.892721217887726, 'recall': 0.8376858175974287, 'f1-score': 0.8643283203979641}, 1: {'precision': 0.7979061090382581, 'recall': 0.8636528028933093, 'f1-score': 0.8294786812168928}, 2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}, 3: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21642)\u001b[0m Client-side evaluation loss 0.004814969782048419 / accuracy 0.8488867227580545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-09 16:20:27,010 | server.py:187 | evaluate_round 4 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-12-09 16:20:27,016 | server.py:222 | fit_round 5: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 5 clients (out of 5)\n",
            "DEBUG flwr 2023-12-09 16:20:57,582 | server.py:236 | fit_round 5 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-12-09 16:20:57,600 | server.py:173 | evaluate_round 5: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m {0: {'precision': 0.8761655566127498, 'recall': 0.961020663744521, 'f1-score': 0.9166334859645631}, 1: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}, 3: {'precision': 0.25903614457831325, 'recall': 0.08989547038327526, 'f1-score': 0.13347128815312984}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m Client-side evaluation loss 0.006142548446487487 / accuracy 0.8479001135073779\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m {0: {'precision': 0.8749342891278376, 'recall': 0.8171755043742189, 'f1-score': 0.8450691222968452}, 1: {'precision': 0.8167388167388168, 'recall': 0.8118276603960942, 'f1-score': 0.8142758334486099}, 2: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}, 3: {'precision': 0.25047619047619046, 'recall': 0.04249474874777832, 'f1-score': 0.07266196988534328}, 4: {'precision': 0, 'recall': 0.0, 'f1-score': 0}}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=21643)\u001b[0m Client-side evaluation loss 0.005206495204567909 / accuracy 0.832175\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-09 16:21:14,773 | server.py:187 | evaluate_round 5 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 5 results and 0 failures\n",
            "INFO flwr 2023-12-09 16:21:14,780 | server.py:153 | FL finished in 251.97685221399934\n",
            "INFO:flwr:FL finished in 251.97685221399934\n",
            "INFO flwr 2023-12-09 16:21:14,785 | app.py:226 | app_fit: losses_distributed [(1, 0.009591201297967476), (2, 0.007217007365723428), (3, 0.006256769237535114), (4, 0.005358124017170198), (5, 0.00521905913886517)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.009591201297967476), (2, 0.007217007365723428), (3, 0.006256769237535114), (4, 0.005358124017170198), (5, 0.00521905913886517)]\n",
            "INFO flwr 2023-12-09 16:21:14,794 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-12-09 16:21:14,798 | app.py:228 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-12-09 16:21:14,808 | app.py:229 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-12-09 16:21:14,810 | app.py:230 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.009591201297967476\n",
              "\tround 2: 0.007217007365723428\n",
              "\tround 3: 0.006256769237535114\n",
              "\tround 4: 0.005358124017170198\n",
              "\tround 5: 0.00521905913886517"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Code"
      ],
      "metadata": {
        "id": "dTqY0XEzXVVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#đoạn code để kiểm tra chương trình chạy đúng không\n",
        "trainloader = trainloaders[0]\n",
        "valloader = valloaders[0]\n",
        "net = Net(param).to(DEVICE)\n",
        "#chạy thử với 5 lần train\n",
        "for epoch in range(2):\n",
        "    train(net, trainloader, 1)\n",
        "    loss, accuracy = test(net, valloader)\n",
        "    print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
        "\n",
        "loss, accuracy = test(net, valloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zewkoqvXXuh",
        "outputId": "2242a8e4-5fa4-44da-8b72-9a65620bb78b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 1: {'precision': 0.9992776413322516, 'recall': 0.9995664595306647, 'f1-score': 0.9994220295654107}, 2: {'precision': 0.037037037037037035, 'recall': 0.012658227848101266, 'f1-score': 0.018867924528301886}, 3: {'precision': 0.998989286436224, 'recall': 0.9803610394762944, 'f1-score': 0.9895875050060071}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\n",
            "Epoch 1: validation loss 0.00023720372456517995, accuracy 0.9989048596851472\n",
            "{0: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 1: {'precision': 0.999144282808975, 'recall': 0.9995886283535128, 'f1-score': 0.9993664061892111}, 2: {'precision': 0.037037037037037035, 'recall': 0.011235955056179775, 'f1-score': 0.017241379310344827}, 3: {'precision': 0.9993935718617344, 'recall': 0.9780415430267062, 'f1-score': 0.9886022795440912}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\n",
            "Epoch 2: validation loss 0.00043522704834746394, accuracy 0.998799557731796\n",
            "{0: {'precision': 0, 'recall': 0.0, 'f1-score': 0}, 1: {'precision': 0.999144282808975, 'recall': 0.9995886283535128, 'f1-score': 0.9993664061892111}, 2: {'precision': 0.037037037037037035, 'recall': 0.011235955056179775, 'f1-score': 0.017241379310344827}, 3: {'precision': 0.9993935718617344, 'recall': 0.9780415430267062, 'f1-score': 0.9886022795440912}, 4: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0}}\n",
            "Final test set performance:\n",
            "\tloss 0.00043522704834746394\n",
            "\taccuracy 0.998799557731796\n"
          ]
        }
      ]
    }
  ]
}